# Image-Captioning
The objective of the project is to generate the captions for the input image. Flickr8k dataset was used. The dataset consists of around 8k images and an average of 5 captions for each image. The features are extracted from both the image and the text captions for input. The features will be concatenated to predict the next word of the caption. CNN is used for image and LSTM is used for text. BLEU Score is used as a metric to evaluate the performance of the trained model.
